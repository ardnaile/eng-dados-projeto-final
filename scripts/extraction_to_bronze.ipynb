{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo coleção: cars\n",
      "mongodb+srv://elimottacardoso:VpLcHPrmkMffxaNq@cluster0.pflgc.mongodb.net\n",
      "car_sales_db\n",
      "cars\n",
      "Erro ao carregar a coleção cars: An error occurred while calling o365.load.\n",
      ": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: com.mongodb.spark.sql.connector.read. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:725)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.lang.ClassNotFoundException: com.mongodb.spark.sql.connector.read.DefaultSource\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:593)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n",
      "\t... 14 more\n",
      "\n",
      "Lendo coleção: sales\n",
      "mongodb+srv://elimottacardoso:VpLcHPrmkMffxaNq@cluster0.pflgc.mongodb.net\n",
      "car_sales_db\n",
      "sales\n",
      "Erro ao carregar a coleção sales: An error occurred while calling o372.load.\n",
      ": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: com.mongodb.spark.sql.connector.read. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:725)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.lang.ClassNotFoundException: com.mongodb.spark.sql.connector.read.DefaultSource\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:593)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n",
      "\t... 14 more\n",
      "\n",
      "Lendo coleção: services\n",
      "mongodb+srv://elimottacardoso:VpLcHPrmkMffxaNq@cluster0.pflgc.mongodb.net\n",
      "car_sales_db\n",
      "services\n",
      "Erro ao carregar a coleção services: An error occurred while calling o379.load.\n",
      ": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: com.mongodb.spark.sql.connector.read. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:725)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.lang.ClassNotFoundException: com.mongodb.spark.sql.connector.read.DefaultSource\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:593)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n",
      "\t... 14 more\n",
      "\n",
      "Lendo coleção: employees\n",
      "mongodb+srv://elimottacardoso:VpLcHPrmkMffxaNq@cluster0.pflgc.mongodb.net\n",
      "car_sales_db\n",
      "employees\n",
      "Erro ao carregar a coleção employees: An error occurred while calling o386.load.\n",
      ": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: com.mongodb.spark.sql.connector.read. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:725)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.lang.ClassNotFoundException: com.mongodb.spark.sql.connector.read.DefaultSource\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:593)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n",
      "\t... 14 more\n",
      "\n",
      "Lendo coleção: payments\n",
      "mongodb+srv://elimottacardoso:VpLcHPrmkMffxaNq@cluster0.pflgc.mongodb.net\n",
      "car_sales_db\n",
      "payments\n",
      "Erro ao carregar a coleção payments: An error occurred while calling o393.load.\n",
      ": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: com.mongodb.spark.sql.connector.read. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:725)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.lang.ClassNotFoundException: com.mongodb.spark.sql.connector.read.DefaultSource\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:593)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n",
      "\t... 14 more\n",
      "\n",
      "Lendo coleção: clients\n",
      "mongodb+srv://elimottacardoso:VpLcHPrmkMffxaNq@cluster0.pflgc.mongodb.net\n",
      "car_sales_db\n",
      "clients\n",
      "Erro ao carregar a coleção clients: An error occurred while calling o400.load.\n",
      ": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: com.mongodb.spark.sql.connector.read. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:725)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor16.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:52)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:580)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: java.lang.ClassNotFoundException: com.mongodb.spark.sql.connector.read.DefaultSource\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:593)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:526)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n",
      "\t... 14 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "\n",
    "# Inicialização do SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Extrair MongoDB para Azure\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:10.4.0\") \\\n",
    "    .config(\"spark.mongodb.read.connection.uri\", os.environ[\"MONGODB_CONNECTION_STRING\"]) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Conexão ao MongoDB para listar coleções\n",
    "client = MongoClient(os.environ[\"MONGODB_CONNECTION_STRING\"])\n",
    "db = client[os.environ[\"MONGODB_DATABASE\"]]\n",
    "collections = db.list_collection_names()\n",
    "\n",
    "# Loop para processar todas as coleções\n",
    "for collection in collections:\n",
    "    print(f\"Lendo coleção: {collection}\")\n",
    "    try:\n",
    "        # Leitura da coleção no MongoDB como DataFrame\n",
    "        print(os.environ[\"MONGODB_CONNECTION_STRING\"])\n",
    "        print(os.environ[\"MONGODB_DATABASE\"])\n",
    "        print(collection)\n",
    "        df = spark.read \\\n",
    "            .format(\"mongodb\") \\\n",
    "            .option(\"uri\", os.environ[\"MONGODB_CONNECTION_STRING\"]) \\\n",
    "            .option(\"database\", os.environ[\"MONGODB_DATABASE\"]) \\\n",
    "            .option(\"collection\", collection) \\\n",
    "            .load()\n",
    "        \n",
    "        # Exibir esquema para depuração (opcional)\n",
    "        df.printSchema()\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar a coleção {collection}: {e}\")\n",
    "    \n",
    "    # # Caminho no Data Lake para salvar\n",
    "    # output_path = f\"{os.environ[\"AZURE_STORAGE_ACCOUNT_URL\"]}/{collection}.parquet\"\n",
    "    \n",
    "    # # Gravação no Data Lake em formato Parquet\n",
    "    # df.write \\\n",
    "    #     .mode(\"overwrite\") \\\n",
    "    #     .parquet(output_path)\n",
    "    \n",
    "    # print(f\"Coleção {collection} salva em {output_path}\")\n",
    "\n",
    "# Encerrar sessão Spark\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
